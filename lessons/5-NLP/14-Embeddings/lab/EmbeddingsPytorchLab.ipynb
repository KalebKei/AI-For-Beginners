{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "667af50a-7029-4fa9-b1c8-1ff0a18e96af",
   "metadata": {},
   "source": [
    "# Kaleb playing around with embeddings...\n",
    "keitorch.py is a modified version of torchnlp ---\n",
    "*which by the way not cool it's named the same as an actual torch library. took me forever to figure that out*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e9998f0-04ad-4a3f-b0ac-cf1a09791a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaleb/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import numpy as np\n",
    "from torchnlp import *\n",
    "from keitorch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48597844-466c-4cc9-ba2b-dc9656e2e820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Building vocab...\n",
      "Vocab size =  519818\n"
     ]
    }
   ],
   "source": [
    "dir = 'data/datasets/YelpReviewFull'\n",
    "train_dataset, test_dataset, classes, vocab = load_dataset_from_csvs(dir=dir)\n",
    "vocab_size = len(vocab)\n",
    "print(\"Vocab size = \",vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0def9b0d-1880-47ba-a790-64fa65beba09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " \"Unfortunately, the frustration of being Dr. Goldberg's patient is a repeat of the experience I've had with so many other doctors in NYC -- good doctor, terrible staff.  It seems that his staff simply never answers the phone.  It usually takes 2 hours of repeated calling to get an answer.  Who has time for that or wants to deal with it?  I have run into this problem with many other doctors and I just don't get it.  You have office workers, you have patients with medical needs, why isn't anyone answering the phone?  It's incomprehensible and not work the aggravation.  It's with regret that I feel that I have to give Dr. Goldberg 2 stars.\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3227f652-c700-4918-8608-bce4cb39facd",
   "metadata": {},
   "source": [
    "## Using both Regular Emed Classifier and Embedding Bag Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5746fb4-d128-4097-b849-195eb322770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbedClassifier(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embed_dim)\n",
    "        self.fc = torch.nn.Linear(embed_dim, num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = torch.mean(x,dim=1)\n",
    "        return self.fc(x)\n",
    "\n",
    "class EmbedBagClassifier(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.EmbeddingBag(vocab_size, embed_dim)\n",
    "        self.fc = torch.nn.Linear(embed_dim, num_class)\n",
    "\n",
    "    def forward(self, text, off):\n",
    "        x = self.embedding(text, off)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9a5b071-35ee-473c-8999-e8a7795f10a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original file does not work as it doesn't use the correct vocab variable\n",
    "\n",
    "def padify(b,voc=vocab,tokenizer=tokenizer):\n",
    "    # b is the list of tuples of length batch_size\n",
    "    #   - first element of a tuple = label, \n",
    "    #   - second = feature (text sequence)\n",
    "    # build vectorized sequence\n",
    "    v = [encode(x[1],voc=voc,tokenizer=tokenizer) for x in b]\n",
    "    # compute max length of a sequence in this minibatch\n",
    "    l = max(map(len,v))\n",
    "    return ( # tuple of two tensors - labels and features\n",
    "        torch.LongTensor([t[0]-1 for t in b]),\n",
    "        torch.stack([torch.nn.functional.pad(torch.tensor(t),(0,l-len(t)),mode='constant',value=0) for t in v])\n",
    "    )\n",
    "\n",
    "def offsetify(b, voc=vocab):\n",
    "    # first, compute data tensor from all sequences\n",
    "    x = [torch.tensor(encode(t[1], voc=voc)) for t in b]\n",
    "    # now, compute the offsets by accumulating the tensor of sequence lengths\n",
    "    o = [0] + [len(t) for t in x]\n",
    "    o = torch.tensor(o[:-1]).cumsum(dim=0)\n",
    "    return ( \n",
    "        torch.LongTensor([t[0]-1 for t in b]), # labels\n",
    "        torch.cat(x), # text \n",
    "        o\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e13786b5-404a-4b58-8421-947bda119f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For regular\n",
    "def train_epoch(net,dataloader,vocab, lr=0.01,optimizer=None,loss_fn = torch.nn.CrossEntropyLoss(),epoch_size=None, report_freq=200):\n",
    "    optimizer = optimizer or torch.optim.Adam(net.parameters(),lr=lr)\n",
    "    loss_fn = loss_fn.to(device)\n",
    "    net.train()\n",
    "    total_loss,acc,count,i = 0,0,0,0\n",
    "    for labels,features in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        # features, labels = torch.tensor(features), torch.tensor(labels)\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        out = net(features)\n",
    "        loss = loss_fn(out,labels) #cross_entropy(out,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss+=loss\n",
    "        _,predicted = torch.max(out,1)\n",
    "        acc+=(predicted==labels).sum()\n",
    "        count+=len(labels)\n",
    "        i+=1\n",
    "        if i%report_freq==0:\n",
    "            print(f\"{count}: acc={acc.item()/count}\")\n",
    "        if epoch_size and count>epoch_size:\n",
    "            break\n",
    "    return total_loss.item()/count, acc.item()/count\n",
    "\n",
    "# For bag\n",
    "def train_epoch_emb(net,dataloader,lr=0.01,optimizer=None,loss_fn = torch.nn.CrossEntropyLoss(),epoch_size=None, report_freq=200):\n",
    "    optimizer = optimizer or torch.optim.Adam(net.parameters(),lr=lr)\n",
    "    loss_fn = loss_fn.to(device)\n",
    "    net.train()\n",
    "    total_loss,acc,count,i = 0,0,0,0\n",
    "    for labels,text,off in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        labels,text,off = labels.to(device), text.to(device), off.to(device)\n",
    "        out = net(text, off)\n",
    "        loss = loss_fn(out,labels) #cross_entropy(out,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss+=loss\n",
    "        _,predicted = torch.max(out,1)\n",
    "        acc+=(predicted==labels).sum()\n",
    "        count+=len(labels)\n",
    "        i+=1\n",
    "        if i%report_freq==0:\n",
    "            print(f\"{count}: acc={acc.item()/count}\")\n",
    "        if epoch_size and count>epoch_size:\n",
    "            break\n",
    "    return total_loss.item()/count, acc.item()/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a85a7da1-2e4e-4812-a613-5330a7606a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting regular embed classifier\n",
      "3200: acc=0.299375\n",
      "6400: acc=0.31234375\n",
      "9600: acc=0.3285416666666667\n",
      "12800: acc=0.34484375\n",
      "16000: acc=0.352125\n",
      "19200: acc=0.359375\n",
      "22400: acc=0.3659375\n",
      "Starting bag embed classifier\n",
      "3200: acc=0.3203125\n",
      "6400: acc=0.3334375\n",
      "9600: acc=0.346875\n",
      "12800: acc=0.358984375\n",
      "16000: acc=0.365375\n",
      "19200: acc=0.369375\n",
      "22400: acc=0.3741964285714286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(26.26945877319258, 0.37703934740882916)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, collate_fn=padify, shuffle=True)\n",
    "\n",
    "print(\"Starting regular embed classifier\")\n",
    "net = EmbedClassifier(vocab_size,32,len(classes)).to(device)\n",
    "train_epoch(net,train_loader,vocab, lr=1, epoch_size=25000)\n",
    "\n",
    "\n",
    "print(\"Starting bag embed classifier\")\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, collate_fn=offsetify, shuffle=True)\n",
    "bagnet = EmbedBagClassifier(vocab_size,32,len(classes)).to(device)\n",
    "train_epoch_emb(bagnet,train_loader, lr=4, epoch_size=25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d961ecf-96c9-4a32-8b37-d19583737e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular testing\n",
      "Test 1\n",
      "Review text: Don't waste your time.  We had two different people come to our house to give us estimates for a deck (one of them the OWNER).  Both times, we never heard from them.  Not a call, not the estimate, nothing..\n",
      " Actual Review: 1, Predicted: 1\n",
      "Test 2\n",
      "Review text: Wast there last Friday. Seats right in front if the stage. The show was good. The headliner, while a bit long, was good. Fantastic service from our waitresses. Will definitely go back..\n",
      " Actual Review: 4, Predicted: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Regular testing\")\n",
    "\n",
    "single_instance = test_dataset[0]\n",
    "\n",
    "# Wrap it in a list to create a batch of size one\n",
    "single_batch = [single_instance]\n",
    "\n",
    "# Apply padify to the single batch\n",
    "labels, text = padify(single_batch)\n",
    "\n",
    "# Move tensors to the device\n",
    "labels, text = labels.to(device), text.to(device)\n",
    "\n",
    "# Pass through the model\n",
    "output = net(text)\n",
    "_,predicted = torch.max(output,1)\n",
    "\n",
    "print(\"Test 1\")\n",
    "print(f\"Review text: {test_dataset[0][1]}.\\n Actual Review: {test_dataset[0][0]}, Predicted: {predicted[0]+1}\")\n",
    "\n",
    "single_instance = test_dataset[14]\n",
    "\n",
    "# Wrap it in a list to create a batch of size one\n",
    "single_batch = [single_instance]\n",
    "\n",
    "# Apply padify to the single batch\n",
    "labels, text = padify(single_batch)\n",
    "\n",
    "# Move tensors to the device\n",
    "labels, text = labels.to(device), text.to(device)\n",
    "\n",
    "# Pass through the model\n",
    "output = net(text)\n",
    "_,predicted = torch.max(output,1)\n",
    "\n",
    "print(\"Test 2\")\n",
    "print(f\"Review text: {test_dataset[14][1]}.\\n Actual Review: {test_dataset[14][0]}, Predicted: {predicted[0]+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d3ebd4e-2925-45ec-b3ae-0dd9a5862588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagnet testing\n",
      "Test 1\n",
      "Review text: Don't waste your time.  We had two different people come to our house to give us estimates for a deck (one of them the OWNER).  Both times, we never heard from them.  Not a call, not the estimate, nothing..\n",
      " Actual Review: 1, Predicted: 1\n",
      "Test 2\n",
      "Review text: Wast there last Friday. Seats right in front if the stage. The show was good. The headliner, while a bit long, was good. Fantastic service from our waitresses. Will definitely go back..\n",
      " Actual Review: 4, Predicted: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Bagnet testing\")\n",
    "\n",
    "single_instance = test_dataset[0]\n",
    "\n",
    "# Wrap it in a list to create a batch of size one\n",
    "single_batch = [single_instance]\n",
    "\n",
    "# Apply offsetify to the single batch\n",
    "labels, text, offsets = offsetify(single_batch)\n",
    "\n",
    "# Move tensors to the device\n",
    "labels, text, offsets = labels.to(device), text.to(device), offsets.to(device)\n",
    "\n",
    "# Pass through the model\n",
    "output = bagnet(text, offsets)\n",
    "_,predicted = torch.max(output,1)\n",
    "\n",
    "print(\"Test 1\")\n",
    "print(f\"Review text: {test_dataset[0][1]}.\\n Actual Review: {test_dataset[0][0]}, Predicted: {predicted[0]+1}\")\n",
    "\n",
    "single_instance = test_dataset[14]\n",
    "\n",
    "# Wrap it in a list to create a batch of size one\n",
    "single_batch = [single_instance]\n",
    "\n",
    "# Apply offsetify to the single batch\n",
    "labels, text, offsets = offsetify(single_batch)\n",
    "\n",
    "# Move tensors to the device\n",
    "labels, text, offsets = labels.to(device), text.to(device), offsets.to(device)\n",
    "\n",
    "# Pass through the model\n",
    "output = bagnet(text, offsets)\n",
    "_,predicted = torch.max(output,1)\n",
    "\n",
    "print(\"Test 2\")\n",
    "print(f\"Review text: {test_dataset[14][1]}.\\n Actual Review: {test_dataset[14][0]}, Predicted: {predicted[0]+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a59f5e-99e1-48b0-ae64-5866d0850443",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
