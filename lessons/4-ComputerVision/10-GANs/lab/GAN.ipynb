{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00d8b00a-a55f-437b-bf14-8c47b8477cd1",
   "metadata": {},
   "source": [
    "# GAN and DCGAN task from Lecture\n",
    "### Transfered to a this directory to keep sanity between the lecture notes and Kaleb's implementation\n",
    "Task description: \"**Task**: Try generating more complex color images with DCGAN - for example, take one class from CIFAR-10 dataset.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fa4240-0662-4ca3-9af2-f8f2102de679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchinfo import summary\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f75ff83-3fd0-42b5-af75-64f49c545468",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85354494-fd40-4d3e-bf28-820e10be2f63",
   "metadata": {},
   "source": [
    "# Shared Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff4ad5d-771a-4b4c-92f1-df18b612d2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 100\n",
    "plot_every = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73b220e-9d35-4db5-8c1d-be05ec14d26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(model):\n",
    "    classname = model.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(model.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(model.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(model.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5509ca54-b72f-4660-a858-2aff8350603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformations for the training and testing sets\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4, padding_mode='reflect'),  # Randomly crop the images\n",
    "    transforms.RandomHorizontalFlip(),     # Randomly flip the images horizontally\n",
    "    transforms.ToTensor(),                 # Convert the images to PyTorch tensors\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),  # Normalize the images\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),                 # Convert the images to PyTorch tensors\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),  # Normalize the images\n",
    "])\n",
    "\n",
    "class SpecificClassDataset(Dataset):\n",
    "    def __init__(self, dataset, target_class):\n",
    "        self.dataset = dataset\n",
    "        self.target_class = target_class\n",
    "        self.indices = [i for i, (_, label) in enumerate(self.dataset) if label == self.target_class]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        original_idx = self.indices[idx]\n",
    "        image, label = self.dataset[original_idx]\n",
    "        return image, label\n",
    "\n",
    "# Load the CIFAR-10 training dataset\n",
    "train_dataset_full = torchvision.datasets.CIFAR10(\n",
    "    root='./data',       # Directory to store the dataset\n",
    "    train=True,          # Specify that this is the training set\n",
    "    transform=transform_train,  # Apply the training transformations\n",
    "    download=True        # Download the dataset if it's not already available\n",
    ")\n",
    "\n",
    "# Load the CIFAR-10 test dataset\n",
    "test_dataset_full = torchvision.datasets.CIFAR10(\n",
    "    root='./data',       # Directory to store the dataset\n",
    "    train=False,         # Specify that this is the test set\n",
    "    transform=transform_test,  # Apply the test transformations\n",
    "    download=True        # Download the dataset if it's not already available\n",
    ")\n",
    "\n",
    "# Specify the class you want to filter\n",
    "target_class = 6 # frogs\n",
    "\n",
    "# Create specific class datasets\n",
    "train_dataset = SpecificClassDataset(train_dataset_full, target_class)\n",
    "test_dataset = SpecificClassDataset(test_dataset_full, target_class)\n",
    "\n",
    "# Create data loaders for the training and testing sets\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,  # The training dataset\n",
    "    batch_size=batch_size,          # Number of samples per batch\n",
    "    shuffle=True,           # Shuffle the data at every epoch\n",
    "    num_workers=2           # Number of subprocesses to use for data loading\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,   # The test dataset\n",
    "    batch_size=batch_size,          # Number of samples per batch\n",
    "    shuffle=False,          # Do not shuffle the data\n",
    "    num_workers=2           # Number of subprocesses to use for data loading\n",
    ")\n",
    "\n",
    "dataloaders = (train_loader, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7a87e7-af25-4007-8e13-931ff265ecd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to unnormalize and show an image\n",
    "def unnormalize(img, mean, std):\n",
    "    img = img.clone()  # Clone to avoid modifying the original tensor\n",
    "    for t, m, s in zip(img, mean, std):\n",
    "        t.mul_(s).add_(m)  # Unnormalize\n",
    "    return img\n",
    "    \n",
    "def imshow(img, title):\n",
    "    img = unnormalize(img, mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))  # Unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Print 5 images from the dataset\n",
    "for i in range(5):\n",
    "    imshow(images[i], f'Label: {labels[i].item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3508b68b-9488-4d6b-8ebc-a20caae5922e",
   "metadata": {},
   "source": [
    "# GAN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa662639-d4e6-4836-ac70-66969ddca2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 1.0\n",
    "lr = 1e-4\n",
    "weight_decay = 8e-9\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc56a0bf-f65a-43a2-bf53-722910e20826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotn(n, generator, device):\n",
    "    generator.eval()\n",
    "    noise = torch.FloatTensor(np.random.normal(0, 1, (n, 100))).to(device)\n",
    "    imgs = generator(noise).detach().cpu()\n",
    "    \n",
    "    # Rescale from [-1, 1] to [0, 1]\n",
    "    imgs = (imgs + 1) / 2\n",
    "    # imgs = torch.clamp(imgs, 0, 1)\n",
    "    fig, ax = plt.subplots(1, n, figsize=(n * 3, 3))\n",
    "    for i, im in enumerate(imgs):\n",
    "        # print(im.shape)\n",
    "        # print(im[0])\n",
    "        ax[i].imshow(np.transpose(im.numpy(), (1, 2, 0)))  # Convert from CHW to HWC format\n",
    "        ax[i].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2f8ae5-2542-44ce-b197-f72e73a31f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(dataloaders, models, optimizers, loss_fn, epochs, plot_every, device):\n",
    "    tqdm_iter = tqdm(range(epochs))\n",
    "    train_dataloader = dataloaders[0]\n",
    "    \n",
    "    gen, disc = models[0], models[1]\n",
    "    optim_gen, optim_disc = optimizers[0], optimizers[1]\n",
    "\n",
    "    for epoch in tqdm_iter:\n",
    "        gen.train()\n",
    "        disc.train()\n",
    "\n",
    "        train_gen_loss = 0.0\n",
    "        train_disc_loss = 0.0\n",
    "        \n",
    "        test_gen_loss = 0.0\n",
    "        test_disc_loss = 0.0\n",
    "\n",
    "        for batch in train_dataloader:\n",
    "            imgs, _ = batch\n",
    "            imgs = imgs.to(device)\n",
    "\n",
    "            disc.eval()\n",
    "            gen.zero_grad()\n",
    "\n",
    "            noise = torch.FloatTensor(np.random.normal(0.0, 1.0, (imgs.shape[0], 100))).to(device)\n",
    "            real_labels = torch.ones((imgs.shape[0], 1)).to(device)\n",
    "            fake_labels = torch.zeros((imgs.shape[0], 1)).to(device)\n",
    "            \n",
    "            generated = gen(noise)\n",
    "            disc_preds = disc(generated)\n",
    "\n",
    "            g_loss = loss_fn(disc_preds, real_labels)\n",
    "            g_loss.backward()\n",
    "            optim_gen.step()\n",
    "\n",
    "            disc.train()\n",
    "            disc.zero_grad()\n",
    "\n",
    "            disc_real = disc(imgs)\n",
    "            disc_real_loss = loss_fn(disc_real, real_labels)\n",
    "\n",
    "            disc_fake = disc(generated.detach())\n",
    "            disc_fake_loss = loss_fn(disc_fake, fake_labels)\n",
    "\n",
    "            d_loss = (disc_real_loss + disc_fake_loss) / 2.0\n",
    "            d_loss.backward()\n",
    "            optim_disc.step()\n",
    "\n",
    "            train_gen_loss += g_loss.item()\n",
    "            train_disc_loss += d_loss.item()\n",
    "\n",
    "        train_gen_loss /= len(train_dataloader)\n",
    "        train_disc_loss /= len(train_dataloader)\n",
    "\n",
    "        if epoch % plot_every == 0 or epoch == epochs - 1:\n",
    "            plotn(5, gen, device)\n",
    "\n",
    "        tqdm_dct = {'generator loss:': train_gen_loss, 'discriminator loss:': train_disc_loss}\n",
    "        tqdm_iter.set_postfix(tqdm_dct, refresh=True)\n",
    "        tqdm_iter.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74020e8e-eaac-4a78-935b-297da5418b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeiGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(100, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256, momentum=0.2)\n",
    "        self.linear2 = nn.Linear(256, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512, momentum=0.2)\n",
    "        self.linear3 = nn.Linear(512, 1024)\n",
    "        self.bn3 = nn.BatchNorm1d(1024, momentum=0.2)\n",
    "        self.linear4 = nn.Linear(1024, 3072)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, input):\n",
    "        hidden1 = self.leaky_relu(self.bn1(self.linear1(input)))\n",
    "        hidden2 = self.leaky_relu(self.bn2(self.linear2(hidden1)))\n",
    "        hidden3 = self.leaky_relu(self.bn3(self.linear3(hidden2)))\n",
    "        generated = self.tanh(self.linear4(hidden3)).view(input.shape[0], 3, 32, 32)\n",
    "        return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d2c83d-b0ec-424d-a92a-7c1c69f0e1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeiDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(3072, 1024)\n",
    "        self.linear2 = nn.Linear(1024, 512)\n",
    "        self.linear3 = nn.Linear(512, 256)\n",
    "        self.linear4 = nn.Linear(256, 1)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.view(input.shape[0], -1)\n",
    "        hidden1 = self.leaky_relu(self.linear1(input))\n",
    "        hidden2 = self.leaky_relu(self.linear2(hidden1))\n",
    "        hidden3 = self.leaky_relu(self.linear3(hidden2))\n",
    "        classififed = self.sigmoid(self.linear4(hidden3))\n",
    "        return classififed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd01f75-f344-41b0-8aba-dab07932a3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = KeiGenerator().to(device)\n",
    "discriminator = KeiDiscriminator().to(device)\n",
    "optimizer_generator = optim.Adam(generator.parameters(), lr=lr, weight_decay=weight_decay, betas=(beta1, beta2))\n",
    "optimizer_discriminator = optim.Adam(discriminator.parameters(), lr=lr, weight_decay=weight_decay, betas=(beta1, beta2))\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "models = (generator, discriminator)\n",
    "optimizers = (optimizer_generator, optimizer_discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39abde10-d077-4422-90f0-346b2535b298",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary(generator,input_size=(1,100)))\n",
    "print(summary(discriminator,input_size=(1,3,32,32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e708b16-1fd3-4630-82d3-fdbbf75c64bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_gan(dataloaders, models, optimizers, loss_fn, epochs, plot_every, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b6669a-6d4e-4b61-9e94-6d44e524d0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "plotn(5, generator, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fe5a16-d46d-45e1-b848-9c7a9ab1697a",
   "metadata": {},
   "source": [
    "# DC GAN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51450a74-1224-44ec-aa12-df4374077635",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 1.0\n",
    "lr = 1e-4\n",
    "weight_decay = 8e-9\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d204ee-05cb-4ce2-aafd-2e6a2c4ce32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeiDCGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()      \n",
    "        self.conv1 = nn.ConvTranspose2d(100, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(1024)\n",
    "        self.conv2 = nn.ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(512)\n",
    "        self.conv3 = nn.ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.conv4 = nn.ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.conv5 = nn.ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input):\n",
    "        # [1, 100, 1, 1]\n",
    "        hidden1 = self.relu(self.bn1(self.conv1(input)))\n",
    "        # [1, 1024, 2, 2]\n",
    "        hidden2 = self.relu(self.bn2(self.conv2(hidden1)))\n",
    "        # [1, 512, 4, 4]\n",
    "        hidden3 = self.relu(self.bn3(self.conv3(hidden2)))\n",
    "        # [1, 256, 8, 8]\n",
    "        hidden4 = self.relu(self.bn4(self.conv4(hidden3)))\n",
    "        # [1, 128, 16, 16]\n",
    "        generated = self.tanh(self.conv5(hidden4))\n",
    "        # [1, 3, 32, 32]\n",
    "        return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834429b7-0ca2-496a-ba58-2e5745ba996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeiDCDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        self.conv5 = nn.Conv2d(512, 1, kernel_size=(2, 2), stride=(1, 1), padding=(0, 0), bias=False)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input):\n",
    "        # [1, 3, 32, 32]\n",
    "        hidden1 = self.leaky_relu(self.conv1(input))\n",
    "        # [1, 64, 16, 16]\n",
    "        hidden2 = self.leaky_relu(self.bn2(self.conv2(hidden1)))\n",
    "        # [1, 128, 8, 8]\n",
    "        # [1, 128, 8, 8]\n",
    "        hidden3 = self.leaky_relu(self.bn3(self.conv3(hidden2)))\n",
    "        # [1, 256, 4, 4]\n",
    "        # [1, 256, 4, 4]\n",
    "        hidden4 = self.leaky_relu(self.bn4(self.conv4(hidden3)))\n",
    "        # [1, 512, 2, 2]\n",
    "        # [1, 512, 2, 2]      \n",
    "        classified = self.sigmoid(self.conv5(hidden4)).view(input.shape[0], -1)\n",
    "        # [1, 1, 1, 1]\n",
    "        # [1, 1]\n",
    "        return classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a20759-bc8d-405f-bab7-ece92fa1db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_generator = KeiDCGenerator().to(device)\n",
    "adv_generator.apply(weights_init)\n",
    "adv_discriminator = KeiDCDiscriminator().to(device)\n",
    "adv_discriminator.apply(weights_init)\n",
    "print(summary(adv_generator,input_size=(1,100,1,1)))\n",
    "print(summary(adv_discriminator,input_size=(64,3,32,32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82d1685-3d57-4162-94db-b8eaab747fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcplotn(n, generator, device):\n",
    "    generator.eval()\n",
    "    noise = torch.FloatTensor(np.random.normal(0, 1, (n, 100, 1, 1))).to(device)\n",
    "    imgs = generator(noise).detach().cpu()\n",
    "    \n",
    "    # Rescale from [-1, 1] to [0, 1]\n",
    "    imgs = (imgs + 1) / 2\n",
    "    fig, ax = plt.subplots(1, n, figsize=(n * 3, 3))\n",
    "    for i, im in enumerate(imgs):\n",
    "        # print(im.shape)\n",
    "        # print(im[0])\n",
    "        ax[i].imshow(np.transpose(im.numpy(), (1, 2, 0)))  # Convert from CHW to HWC format\n",
    "        ax[i].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735ebd32-9608-4077-bf62-a38d71e09f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dcgan(dataloaders, models, optimizers, loss_fn, epochs, plot_every, device):\n",
    "    tqdm_iter = tqdm(range(epochs))\n",
    "    train_dataloader = dataloaders[0]\n",
    "    \n",
    "    gen, disc = models[0], models[1]\n",
    "    optim_gen, optim_disc = optimizers[0], optimizers[1]\n",
    "    \n",
    "    gen.train()\n",
    "    disc.train()\n",
    "\n",
    "    for epoch in tqdm_iter:\n",
    "        train_gen_loss = 0.0\n",
    "        train_disc_loss = 0.0\n",
    "        \n",
    "        test_gen_loss = 0.0\n",
    "        test_disc_loss = 0.0\n",
    "\n",
    "        for batch in train_dataloader:\n",
    "            imgs, _ = batch\n",
    "            imgs = imgs.to(device)\n",
    "            imgs = 2.0 * imgs - 1.0\n",
    "\n",
    "            gen.zero_grad()\n",
    "\n",
    "            noise = torch.FloatTensor(np.random.normal(0.0, 1.0, (imgs.shape[0], 100, 1, 1))).to(device)\n",
    "            real_labels = torch.ones((imgs.shape[0], 1)).to(device)\n",
    "            fake_labels = torch.zeros((imgs.shape[0], 1)).to(device)\n",
    "            # print(imgs.shape[1])\n",
    "            generated = gen(noise)\n",
    "            disc_preds = disc(generated)\n",
    "\n",
    "            # print(f\"Disc_preds: {disc_preds}\\nReal: {real_labels}\")\n",
    "            g_loss = loss_fn(disc_preds, real_labels)\n",
    "            g_loss.backward()\n",
    "            optim_gen.step()\n",
    "\n",
    "            disc.zero_grad()\n",
    "            disc_real = disc(imgs)\n",
    "            disc_real_loss = loss_fn(disc_real, real_labels)\n",
    "\n",
    "            disc_fake = disc(generated.detach())\n",
    "            disc_fake_loss = loss_fn(disc_fake, fake_labels)\n",
    "\n",
    "            d_loss = (disc_real_loss + disc_fake_loss) / 2.0\n",
    "            d_loss.backward()\n",
    "            optim_disc.step()\n",
    "\n",
    "            train_gen_loss += g_loss.item()\n",
    "            train_disc_loss += d_loss.item()\n",
    "\n",
    "        train_gen_loss /= len(train_dataloader)\n",
    "        train_disc_loss /= len(train_dataloader)\n",
    "\n",
    "        if epoch % plot_every == 0 or epoch == epochs - 1:\n",
    "            dcplotn(5, gen, device)\n",
    "\n",
    "        tqdm_dct = {'generator loss:': train_gen_loss, 'discriminator loss:': train_disc_loss}\n",
    "        tqdm_iter.set_postfix(tqdm_dct, refresh=True)\n",
    "        tqdm_iter.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccf3b2d-6b3d-470b-8a14-f2de7ff86aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_generator = optim.Adam(adv_generator.parameters(), lr=lr, weight_decay=weight_decay, betas=(beta1, beta2))\n",
    "optimizer_discriminator = optim.Adam(adv_discriminator.parameters(), lr=lr, weight_decay=weight_decay, betas=(beta1, beta2))\n",
    "loss_fn = nn.BCELoss()\n",
    "adv_models = (adv_generator, adv_discriminator)\n",
    "adv_optimizers = (optimizer_generator, optimizer_discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5f409d-040f-418e-ab10-7f9f3ddd60e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dcgan(dataloaders, adv_models, adv_optimizers, loss_fn, epochs, plot_every, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d90a1e-4a44-4c5f-b0fb-7c1126c19f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_generator.eval()\n",
    "dcplotn(5, adv_generator, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-env",
   "language": "python",
   "name": "ai-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
