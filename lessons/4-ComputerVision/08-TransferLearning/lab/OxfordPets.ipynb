{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Pet's Real-Life Images\n",
    "\n",
    "Lab Assignment from [AI for Beginners Curriculum](https://github.com/microsoft/ai-for-beginners).\n",
    "\n",
    "Now it's time to deal with more challenging task - classification of the original [Oxford-IIIT Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/). Let's start by loading and visualizing the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
    "# !tar xfz images.tar.gz\n",
    "# !rm images.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define generic function to display a series of images from a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# def display_images(l,titles=None,fontsize=12):\n",
    "#     n=len(l)\n",
    "#     fig,ax = plt.subplots(1,n)\n",
    "#     for i,im in enumerate(l):\n",
    "#         ax[i].imshow(im)\n",
    "#         ax[i].axis('off')\n",
    "#         if titles is not None:\n",
    "#             ax[i].set_title(titles[i],fontsize=fontsize)\n",
    "#     fig.set_size_inches(fig.get_size_inches()*n)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that all images are located in one directory called `images`, and their name contains the name of the class (breed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fnames = os.listdir('images')[:5]\n",
    "# display_images([Image.open(os.path.join('images',x)) for x in fnames],titles=fnames,fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify classification and use the same approach to loading images as in the previous part, let's sort all images into corresponding directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fn in os.listdir('images'):\n",
    "#     cls = fn[:fn.rfind('_')].lower()\n",
    "#     os.makedirs(os.path.join('images',cls),exist_ok=True)\n",
    "#     os.replace(os.path.join('images',fn),os.path.join('images',cls,fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also define the number of classes in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(os.listdir('images'))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing dataset for Deep Learning\n",
    "\n",
    "To start training our neural network, we need to convert all images to tensors, and also create tensors corresponding to labels (class numbers). Most neural network frameworks contain simple tools for dealing with images:\n",
    "* In Tensorflow, use `tf.keras.preprocessing.image_dataset_from_directory`\n",
    "* In PyTorch, use `torchvision.datasets.ImageFolder`\n",
    "\n",
    "As you have seen from the pictures above, all of them are close to square image ratio, so we need to resize all images to square size. Also, we can organize images in minibatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARE THE DATASET\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "std_normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225])\n",
    "trans = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(256),\n",
    "        transforms.ToTensor(), \n",
    "        std_normalize])\n",
    "\n",
    "dataset = datasets.ImageFolder('images', transform= trans)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to separate dataset into train and test portions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT INTO TRAIN-TEST DATASETS\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Calculate the lengths of splits\n",
    "total_len = len(dataset)\n",
    "train_len = int(total_len * 0.67)\n",
    "test_len = total_len - train_len\n",
    "\n",
    "# Create the random splits\n",
    "train_dataset, test_dataset = random_split(dataset, [train_len, test_len])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define data loaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE DATA LOADERS if needed\n",
    "# Create data loaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "print(len(train_dataloader))\n",
    "print(len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [OPTIONAL] Plot the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a neural network\n",
    "\n",
    "For image classification, you should probably define a convolutional neural network with several layers. What to keep an eye for:\n",
    "* Keep in mind the pyramid architecture, i.e. number of filters should increase as you go deeper\n",
    "* Do not forget activation functions between layers (ReLU) and Max Pooling\n",
    "* Final classifier can be with or without hidden layers, but the number of output neurons should be equal to number of classes.\n",
    "\n",
    "An important thing is to get the activation function on the last layer + loss function right:\n",
    "* In Tensorflow, you can use `softmax` as the activation, and `sparse_categorical_crossentropy` as loss. The difference between sparse categorical cross-entropy and non-sparse one is that the former expects output as the number of class, and not as one-hot vector.\n",
    "* In PyTorch, you can have the final layer without activation function, and use `CrossEntropyLoss` loss function. This function applies softmax automatically. \n",
    "\n",
    "> **Hint:** In PyTorch, you can use `LazyLinear` layer instead of `Linear`, in order to avoid computing the number of inputs. It only requires one `n_out` parameter, which is number of neurons in the layer, and the dimension of input data is picked up automatically upon first `forward` pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchinfo import summary\n",
    "\n",
    "torch.__version__\n",
    "# Kaleb code\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE NEURAL NETWORK ARCHITECTURE\n",
    "import torch.nn as nn\n",
    "class KeiNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KeiNet, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=3,out_channels=9,kernel_size=(5,5))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(571536,37)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # [3, 256, 256]\n",
    "        x = nn.functional.relu(self.conv(x))\n",
    "        # [9, 252, 252]\n",
    "        x = self.flatten(x)\n",
    "        # [571536]\n",
    "        x = nn.functional.log_softmax(self.fc(x),dim=1)\n",
    "        # [37]\n",
    "        return x\n",
    "\n",
    "test_net = KeiNet().to(device)\n",
    "print(summary(test_net,input_size=(1,3,256,256)))\n",
    "\n",
    "class KeiNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KeiNet2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=8,kernel_size=(3,3))\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8,out_channels=32,kernel_size=(3,3))\n",
    "        self.conv3 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=(3,3))\n",
    "        self.conv4 = nn.Conv2d(in_channels=64,out_channels=128,kernel_size=(3,3))\n",
    "        self.conv5 = nn.Conv2d(in_channels=128,out_channels=256,kernel_size=(3,3))\n",
    "        # self.conv6 = nn.Conv2d(in_channels=512,out_channels=1024,kernel_size=(3,3))\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(36864,1024)\n",
    "        self.fc2 = nn.Linear(1024,512)\n",
    "        self.fc3 = nn.Linear(512,37)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # [3, 256, 256]\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        # [8, 254, 254]\n",
    "        x = self.pool(x)\n",
    "        # [8, 127, 127]\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        # [32, 125, 125]\n",
    "        x = self.pool(x)\n",
    "        # [32, 62, 62]\n",
    "        x = nn.functional.relu(self.conv3(x))\n",
    "        # [64, 60, 60]\n",
    "        x = self.pool(x)\n",
    "        # [64, 30, 30]\n",
    "        x = nn.functional.relu(self.conv4(x))\n",
    "        # [128, 28, 28]\n",
    "        x = self.pool(x)\n",
    "        # [256, 14, 14]\n",
    "        x = nn.functional.relu(self.conv5(x))\n",
    "        # [256, 12, 12]\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        x = self.flat(x)\n",
    "        # [1, 230400]\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        \n",
    "        return x\n",
    "test_net_adv = KeiNet2().to(device)\n",
    "print(summary(test_net_adv,input_size=(1,3,256,256)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "\n",
    "Now we are ready to train the neural network. During training, please collect accuracy on train and test data on each epoch, and then plot the accuracy to see if there is overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN THE NEURAL NETWORK CODE AND PLOT CODE\n",
    "def train(net, dataloader_train, dataloader_test, epochs = 25, lr = 0.001, verbose = False):\n",
    "    # Initialize output\n",
    "    train_loss, train_acc = [],[]\n",
    "    test_loss, test_acc = [],[]\n",
    "\n",
    "    # Select necissary loss functions, optimizer, etc.\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    # Begin training process\n",
    "    for ep in range(epochs):\n",
    "        train_loss_list, test_loss_list = [], []\n",
    "        sum_train_acc, sum_test_acc = [],[]\n",
    "\n",
    "        # Training\n",
    "        net.train()\n",
    "        for X, y in dataloader_train:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Make predictions and loss calculations\n",
    "            pred = net(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "            train_loss_list.append(loss.item())\n",
    "\n",
    "            # Back prop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Batch accuracy calculations\n",
    "            class_pred = torch.argmax(pred, axis=1)\n",
    "            correct = (class_pred == y).sum()\n",
    "            curr_acc = correct / len(y)\n",
    "            sum_train_acc.append(curr_acc)\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "        temp_acc = (sum(sum_train_acc) / len(sum_train_acc)).cpu().detach().numpy()\n",
    "        train_acc.append(temp_acc)\n",
    "        if verbose:\n",
    "            print(f\"Epoch {ep} TRAIN last loss: {round(loss.item(), 4)}, average accuracy: {round(temp_acc * 100,4)}%\")\n",
    "        \n",
    "        # Evaluating\n",
    "        net.eval()\n",
    "        for X, y in dataloader_test:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Make predictions and loss calculations\n",
    "            pred = net(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "             # Batch accuracy calculations\n",
    "            class_pred = torch.argmax(pred, axis=1)\n",
    "            correct = (class_pred == y).sum()\n",
    "            curr_acc = correct / len(y)\n",
    "            sum_test_acc.append(curr_acc)\n",
    "\n",
    "        test_loss.append(loss.item())\n",
    "        temp_acc = (sum(sum_test_acc) / len(sum_test_acc)).cpu().detach().numpy()\n",
    "        test_acc.append(temp_acc)\n",
    "        if verbose:\n",
    "            print(f\"Epoch {ep} TEST last loss: {round(loss.item(),4)}, average accuracy: {round(temp_acc * 100,4)}%\")\n",
    "        \n",
    "            \n",
    "    \n",
    "    return train_loss, train_acc, test_loss, test_acc\n",
    "\n",
    "\n",
    "\n",
    "def graph_loss_acc(train_loss_list, train_acc_list, test_loss_list, test_acc_list):\n",
    "    epochs = range(1, len(train_loss_list) + 1)\n",
    "    plt.plot(epochs, train_loss_list, label='Training Loss')\n",
    "    plt.plot(epochs, test_loss_list, label='Testing Loss')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title('Loss')\n",
    "    plt.show()\n",
    "    plt.plot(epochs, train_acc_list, label='Training Accuracy')\n",
    "    plt.plot(epochs, test_acc_list, label='Testing Accuracy')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Percent')\n",
    "    plt.title('Training Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TRAIN AND PLOT\n",
    "convnet = KeiNet2().to(device)\n",
    "epochs = 10\n",
    "lr = 0.0005\n",
    "train_loss_list, train_acc_list, test_loss_list, test_acc_list = train(convnet, train_dataloader, test_dataloader, epochs=epochs, lr=lr, verbose=True)\n",
    "graph_loss_acc(train_loss_list, train_acc_list, test_loss_list, test_acc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if you have done everything correctly, you will probably see that the accuracy is quite low.\n",
    "\n",
    "## Transfer Learning\n",
    "\n",
    "To improve the accuracy, let's use pre-trained neural network as feature extractor. Feel free to experiment with VGG-16/VGG-19 models, ResNet50, etc.\n",
    "\n",
    "> Since this training is slower, you may start with training the model for the small number of epochs, eg. 3. You can always resume training to further improve accuracy if needed.\n",
    "\n",
    "We need to normalize our data differently for transfer learning, thus we will reload the dataset again using different set of transforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THE DATASET\n",
    "# Perform standard transformations for VGG-16/VGG-19 if needed \n",
    "std_normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225])\n",
    "trans = transforms.Compose([\n",
    "        transforms.Resize(244),\n",
    "        transforms.CenterCrop(244),\n",
    "        transforms.ToTensor(), \n",
    "        std_normalize])\n",
    "\n",
    "dataset = datasets.ImageFolder('images', transform= trans)\n",
    "print(len(dataset))\n",
    "\n",
    "train_dataset_vgg, test_dataset_vgg = random_split(dataset, [train_len, test_len])\n",
    "\n",
    "\n",
    "train_dataloader_vgg = DataLoader(train_dataset_vgg, batch_size=32, shuffle=True)\n",
    "test_dataloader_vgg = DataLoader(test_dataset_vgg, batch_size=32, shuffle=True)\n",
    "print(len(train_dataloader_vgg))\n",
    "print(len(test_dataloader_vgg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the pre-trained network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "vgg = torchvision.models.vgg16(pretrained=True)\n",
    "summary(vgg,input_size=(1,3,244,244))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define the classification model for your problem:\n",
    "* In PyTorch, there is a slot called `classifier`, which you can replace with your own classifier for the desired number of classes.\n",
    "* In TensorFlow, use VGG network as feature extractor, and build a `Sequential` model with VGG as first layer, and your own classifier on top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD MODEL for your problem with your own linear layers\n",
    "vgg.classifier = torch.nn.Linear(512*7*7,37).to(device)\n",
    "\n",
    "\n",
    "summary(vgg,(1, 3,244,244))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to set all parameters of VGG feature extractor not to be trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE VGG Layers not trainable\n",
    "for x in vgg.features.parameters():\n",
    "    x.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start the training. Be very patient, as training takes a long time, and our train function is not designed to print anything before the end of the epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN THE MODEL\n",
    "epochs = 3\n",
    "lr = 0.0005\n",
    "train_loss_list_vgg, train_acc_list_vgg, test_loss_list_vgg, test_acc_list_vgg = train(vgg, train_dataloader_vgg, test_dataloader_vgg, epochs=epochs, lr=lr, verbose=True)\n",
    "graph_loss_acc(train_loss_list_vgg, train_acc_list_vgg, test_loss_list_vgg, test_acc_list_vgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems much better now!\n",
    "\n",
    "## Optional: Calculate Top 3 Accuracy\n",
    "\n",
    "We can also computer Top 3 accuracy using the same code as in the previous exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATE TOP-3 Accuracy of the model"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86193a1ab0ba47eac1c69c1756090baa3b420b3eea7d4aafab8b85f8b312f0c5"
  },
  "kernelspec": {
   "display_name": "ai-env",
   "language": "python",
   "name": "ai-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
